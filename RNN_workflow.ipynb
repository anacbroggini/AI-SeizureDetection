{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source import data_import\n",
    "from source.constants import CHANNELS, DEFAULT_PATIENTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "\n",
    "from source.filter_eeg_channels import filter_eeg_channels\n",
    "from source.calculate_mean_psd import calculate_mean_psd\n",
    "from source.constants import CHANNELS, FREQUENCY_RANGES\n",
    "                                            \n",
    "from sklearn.preprocessing import StandardScaler, minmax_scale, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_name):\n",
    "    if file_name.endswith('.arrow'):\n",
    "        return data_import.load_pyarrow(file_name=file_name)\n",
    "    elif file_name.endswith('.npy'):\n",
    "        print('loading npy')\n",
    "        return np.load('data/' + file_name, allow_pickle=True)\n",
    "    else:\n",
    "        print('no filename provided, trying npy')\n",
    "        try:\n",
    "            np.load('data/' + file_name + '.npy', allow_pickle=True)\n",
    "        except FileNotFoundError:\n",
    "            print('no npy file found, trying arrow')\n",
    "            return data_import.load_pyarrow(file_name=file_name + '.arrow')\n",
    "        \n",
    "def save_file(data, file_name):\n",
    "    if file_name is None:\n",
    "        print('skipping save file.')\n",
    "    elif file_name.endswith('.arrow'):\n",
    "        data_import.save_pyarrow(data, file_name=file_name)\n",
    "    elif file_name.endswith('.npy'):\n",
    "        print('saving npy')\n",
    "        np.save('data/' + file_name, data)\n",
    "    else:\n",
    "        print('no filetype provided, saving as npy')\n",
    "        np.save('data/' + file_name + '.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMETERS ##\n",
    "SKIP_DATA = False\n",
    "data_filename = \"processed_data.arrow\" # data will be loaded/saved with this filename. Put None to skip saving the file\n",
    "\n",
    "SKIP_FEATURES = False\n",
    "feature_filename = 'extracted_features.npy' # data will be loaded/saved with this filename. Put None to skip saving the file\n",
    "\n",
    "### DATA ###\n",
    "# Load Patient Data #\n",
    "patient_ids = DEFAULT_PATIENTS #DEFAULT_PATIENTS # use DEFAULT_PATIENTS for default patients selection\n",
    "nr_segments=60\n",
    "segment_duration=1\n",
    "ictal_segmentation_foo=data_import.preictal_segmentation\n",
    "interictal_segmentation_foo=data_import.inter_segmentation\n",
    "channels=CHANNELS\n",
    "seizure_offset=0\n",
    "\n",
    "# filter #\n",
    "exclude_ranges=[[58, 62], [118, 122]]\n",
    "\n",
    "### FEATURES ###\n",
    "target_colname = 'target'\n",
    "PRED_INTERVAL = 6000 # how long should a segment count as preictal in seconds\n",
    "\n",
    "window_size = 30 # Define the sequence_train window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chb01_01.edf was import but not resampled 256Hz.\n",
      "chb01_02.edf was import but not resampled 256Hz.\n",
      "chb01_03.edf was import but not resampled 256Hz.\n",
      "chb01_03.edf seizure and buffer was labeled\n",
      "chb01_04.edf was import but not resampled 256Hz.\n",
      "chb01_04.edf seizure and buffer was labeled\n",
      "chb01_05.edf was import but not resampled 256Hz.\n",
      "chb01_06.edf was import but not resampled 256Hz.\n",
      "chb01_07.edf was import but not resampled 256Hz.\n",
      "chb01_08.edf was import but not resampled 256Hz.\n",
      "chb01_09.edf was import but not resampled 256Hz.\n",
      "chb01_10.edf was import but not resampled 256Hz.\n",
      "chb01_11.edf was import but not resampled 256Hz.\n",
      "chb01_12.edf was import but not resampled 256Hz.\n",
      "chb01_13.edf was import but not resampled 256Hz.\n",
      "chb01_14.edf was import but not resampled 256Hz.\n",
      "chb01_15.edf was import but not resampled 256Hz.\n",
      "chb01_15.edf seizure and buffer was labeled\n",
      "chb01_16.edf was import but not resampled 256Hz.\n",
      "chb01_16.edf seizure and buffer was labeled\n",
      "chb01_17.edf was import but not resampled 256Hz.\n",
      "chb01_18.edf was import but not resampled 256Hz.\n",
      "chb01_18.edf seizure and buffer was labeled\n",
      "chb01_19.edf was import but not resampled 256Hz.\n",
      "chb01_20.edf was import but not resampled 256Hz.\n",
      "chb01_21.edf was import but not resampled 256Hz.\n",
      "chb01_21.edf seizure and buffer was labeled\n",
      "chb01_22.edf was import but not resampled 256Hz.\n",
      "chb01_23.edf was import but not resampled 256Hz.\n",
      "chb01_24.edf was import but not resampled 256Hz.\n",
      "chb01_25.edf was import but not resampled 256Hz.\n",
      "chb01_26.edf was import but not resampled 256Hz.\n",
      "chb01_26.edf seizure and buffer was labeled\n",
      "chb01_27.edf was import but not resampled 256Hz.\n",
      "chb01_29.edf was import but not resampled 256Hz.\n",
      "chb01_30.edf was import but not resampled 256Hz.\n",
      "chb01_31.edf was import but not resampled 256Hz.\n",
      "chb01_32.edf was import but not resampled 256Hz.\n",
      "chb01_33.edf was import but not resampled 256Hz.\n",
      "chb01_34.edf was import but not resampled 256Hz.\n",
      "chb01_36.edf was import but not resampled 256Hz.\n",
      "chb01_37.edf was import but not resampled 256Hz.\n",
      "chb01_38.edf was import but not resampled 256Hz.\n",
      "chb01_39.edf was import but not resampled 256Hz.\n",
      "chb01_40.edf was import but not resampled 256Hz.\n",
      "chb01_41.edf was import but not resampled 256Hz.\n",
      "chb01_42.edf was import but not resampled 256Hz.\n",
      "chb01_43.edf was import but not resampled 256Hz.\n",
      "chb01_46.edf was import but not resampled 256Hz.\n",
      "reached_file_start 0\n",
      "reached_file_end 0\n",
      "seizure_too_small 0\n",
      "overlapping_seizure 0\n",
      "ictal_epochs 0\n",
      "preictal_epochs 7\n",
      "interictal_epochs 35\n",
      "seizure_max_reached 0\n",
      "incomplete_channels 0\n",
      "/home/weasel/reps/ai-seizure-detectives/source/../data/processed_data.arrow was successfully written.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of channel                        F4-C4      F3-C3   FT9-FT10      FZ-CZ  \\\n",
       "0 days 00:30:00            16.878726  20.334213  -3.322584  17.941953   \n",
       "0 days 00:30:00.003906250  22.891349  24.865283  -8.175141  23.784967   \n",
       "0 days 00:30:00.007812500  22.162881  25.360125  -8.902114  25.615925   \n",
       "0 days 00:30:00.011718750  29.573426  33.953147 -14.930178  33.038895   \n",
       "0 days 00:30:00.015625     21.292400  18.163275 -11.955401  21.366748   \n",
       "...                              ...        ...        ...        ...   \n",
       "0 days 00:30:59.980468750  14.606619  38.625778 -33.971210 -47.037566   \n",
       "0 days 00:30:59.984375    -14.157892  35.028692 -12.626489  19.119589   \n",
       "0 days 00:30:59.988281250  -6.142158  29.984239   6.891542 -30.945329   \n",
       "0 days 00:30:59.992187500  -7.461311  31.703687  11.110258  -0.631780   \n",
       "0 days 00:30:59.996093750 -25.057236  32.478871 -31.257322  45.032384   \n",
       "\n",
       "channel                        F7-T7     FP2-F4    T8-P8-1    T8-P8-0  \\\n",
       "0 days 00:30:00            18.739373  33.092935  12.625819  12.625819   \n",
       "0 days 00:30:00.003906250  26.448730  40.639022  11.874291  11.874291   \n",
       "0 days 00:30:00.007812500  27.023819  40.074853   5.285063   5.285063   \n",
       "0 days 00:30:00.011718750  32.700204  52.956037   8.308854   8.308854   \n",
       "0 days 00:30:00.015625     20.938086  35.328903  -1.132117  -1.132117   \n",
       "...                              ...        ...        ...        ...   \n",
       "0 days 00:30:59.980468750  38.681257 -16.172219  15.650487  15.650487   \n",
       "0 days 00:30:59.984375     27.590380   0.048707  10.182621  10.182621   \n",
       "0 days 00:30:59.988281250  33.822614  -6.076039  11.431317  11.431317   \n",
       "0 days 00:30:59.992187500  47.133575   4.243125   2.244765   2.244765   \n",
       "0 days 00:30:59.996093750  38.112034  20.242220   8.493927   8.493927   \n",
       "\n",
       "channel                       FP1-F3      CZ-PZ  before_seizure  is_seizure  \\\n",
       "0 days 00:30:00            44.788430   2.790970           False       False   \n",
       "0 days 00:30:00.003906250  59.506243   4.538652           False       False   \n",
       "0 days 00:30:00.007812500  60.136641   5.292160           False       False   \n",
       "0 days 00:30:00.011718750  79.842157   8.558853           False       False   \n",
       "0 days 00:30:00.015625     60.607725   6.096930           False       False   \n",
       "...                              ...        ...             ...         ...   \n",
       "0 days 00:30:59.980468750   1.070482  88.798160           False       False   \n",
       "0 days 00:30:59.984375    -11.140899  47.793463           False       False   \n",
       "0 days 00:30:59.988281250 -17.297052 -70.170586           False       False   \n",
       "0 days 00:30:59.992187500  -5.351621  98.723653           False       False   \n",
       "0 days 00:30:59.996093750   3.774104  74.163589           False       False   \n",
       "\n",
       "channel                   target  epoch  segment_id  \n",
       "0 days 00:30:00           0 days      0           0  \n",
       "0 days 00:30:00.003906250 0 days      0           0  \n",
       "0 days 00:30:00.007812500 0 days      0           0  \n",
       "0 days 00:30:00.011718750 0 days      0           0  \n",
       "0 days 00:30:00.015625    0 days      0           0  \n",
       "...                          ...    ...         ...  \n",
       "0 days 00:30:59.980468750 0 days     41          59  \n",
       "0 days 00:30:59.984375    0 days     41          59  \n",
       "0 days 00:30:59.988281250 0 days     41          59  \n",
       "0 days 00:30:59.992187500 0 days     41          59  \n",
       "0 days 00:30:59.996093750 0 days     41          59  \n",
       "\n",
       "[645120 rows x 15 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not SKIP_DATA:\n",
    "    # Load Patient Data\n",
    "    p_df = data_import.load_segmented_data(patient_ids=patient_ids,\n",
    "                                            nr_segments=nr_segments,\n",
    "                                            segment_duration=segment_duration,\n",
    "                                            ictal_segmentation_foo=data_import.preictal_segmentation,\n",
    "                                            interictal_segmentation_foo=data_import.inter_segmentation,\n",
    "                                            channels=channels,\n",
    "                                            seizure_offset=seizure_offset\n",
    "                                            )\n",
    "    \n",
    "    # Filter\n",
    "    fit_df = filter_eeg_channels(p_df, CHANNELS, fs=256, exclude_ranges=exclude_ranges, Q=30)\n",
    "    pd_toconcat = p_df[['epoch', 'segment_id']]\n",
    "    fit_df = pd.concat(objs=[fit_df, pd_toconcat], axis =1)\n",
    "    save_file(data=fit_df, file_name=data_filename)\n",
    "else:\n",
    "    fit_df = load_file(data_filename)\n",
    "    fit_df = pd.DataFrame(fit_df)\n",
    "fit_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### aggregate Functions for mean psd:\n",
    "delta = lambda x: calculate_mean_psd(x, frequency_ranges={'Delta' : FREQUENCY_RANGES['Delta']})[x.name]['Delta']\n",
    "theta = lambda x: calculate_mean_psd(x, frequency_ranges={'Theta' : FREQUENCY_RANGES['Theta']})[x.name]['Theta']\n",
    "gamma = lambda x: calculate_mean_psd(x, frequency_ranges={'Gamma': FREQUENCY_RANGES['Gamma']})[x.name]['Gamma']\n",
    "\n",
    "delta_agg = pd.NamedAgg(column='delta', aggfunc=delta)\n",
    "theta_agg = pd.NamedAgg(column='theta', aggfunc=theta)\n",
    "gamma_agg = pd.NamedAgg(column='gamma', aggfunc=gamma)\n",
    "\n",
    "### aggregate mean features:\n",
    "abs_mean = lambda x: x.apply(abs).mean()\n",
    "abs_mean_agg = pd.NamedAgg(column='abs_mean', aggfunc=abs_mean)\n",
    "\n",
    "### aggregate Functions for target:\n",
    "target_foo = lambda x, pred_interval=PRED_INTERVAL: 0 < x.dt.total_seconds().min() < pred_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1271, 30, 63)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not SKIP_FEATURES:\n",
    "    # aggregate features\n",
    "    df_features = fit_df.groupby(['epoch', 'segment_id']).agg(\n",
    "        {C:['std',\n",
    "            'var',\n",
    "            #'mean',\n",
    "            abs_mean_agg,\n",
    "            delta_agg,\n",
    "            theta_agg,\n",
    "            gamma_agg\n",
    "            ] for C in CHANNELS} | \n",
    "        {target_colname: [target_foo]} \n",
    "        ) \n",
    "\n",
    "    # joining column names with agg functions, but leaving target column\n",
    "    df_features.columns = ['_'.join(col).strip() for col in df_features.columns.values if target_colname != col[0]] + [target_colname]\n",
    "    df_features.reset_index(inplace=True)\n",
    "\n",
    "    # Scaling the features\n",
    "    num_features= df_features.drop(['epoch','segment_id','target'],axis =1)\n",
    "    scaler = StandardScaler()\n",
    "    num_features_scaled = scaler.fit_transform(num_features)\n",
    "\n",
    "    original_array = np.array(df_features)\n",
    "    target = original_array[:,-1]\n",
    "    target = target[:, np.newaxis]\n",
    "    segseiz_column = original_array[:, 0:2] ## epoch and segment_id\n",
    "    array_all_scaled = np.concatenate((segseiz_column, num_features_scaled, target), axis=1)\n",
    "    array_all_scaled.shape\n",
    "\n",
    "    ### Reshape Array ###\n",
    "    original_array =np.array(df_features)\n",
    "\n",
    "    # Extract the epoch column\n",
    "    epoch_column = original_array[:, 0]\n",
    "\n",
    "    # Determine the number of epochs (assuming epochs are from 1 to number of segments)\n",
    "    num_epochs = df_features.epoch.unique()[-1]\n",
    "\n",
    "    # Determine the number of segments for each epoch\n",
    "    num_segments = len(df_features.segment_id.unique())  # Assuming there are 30 segments for each epoch\n",
    "\n",
    "    # Initialize an empty 3D array\n",
    "    reshaped_array = np.empty((num_epochs,num_segments, array_all_scaled.shape[1]))\n",
    "\n",
    "    # Reshape the data for each epoch and insert it into the 3D array\n",
    "    for epoch in range(num_epochs):\n",
    "        start_idx = epoch * num_segments\n",
    "        end_idx = (epoch + 1) * num_segments\n",
    "        reshaped_array[epoch,:, :] = array_all_scaled[start_idx:end_idx,:]\n",
    "\n",
    "    ### Create Sequence Trains ###\n",
    "    # Assuming original_data_array has dimensions (batch, sequence, features)\n",
    "    num_batches, num_sequences, num_features = reshaped_array.shape\n",
    "\n",
    "    # Calculate the number of augmented batches\n",
    "    num_augmented_batches = num_sequences - window_size + 1\n",
    "    print(f\"num_augmented_batches: {num_augmented_batches}\")\n",
    "\n",
    "    # Create an empty array for the augmented data\n",
    "    data = np.zeros((num_batches * num_augmented_batches, window_size, num_features))\n",
    "    print(f\"data.shape: {data.shape}\")\n",
    "\n",
    "    # Iterate through batches\n",
    "    for batch_idx in range(num_batches):\n",
    "        # Iterate through sequences to create augmented batches\n",
    "        for seq_idx in range(num_augmented_batches):\n",
    "            # Copy the window of data\n",
    "            data[batch_idx * num_augmented_batches + seq_idx, :, :] = reshaped_array[batch_idx, seq_idx:seq_idx + window_size, :]\n",
    "\n",
    "    save_file(data=data, file_name=feature_filename)\n",
    "else:\n",
    "    data = load_file(feature_filename)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data already loaded in parent notebook\n",
      "train shape (992, 30, 62)\n",
      "test shape (279, 30, 62)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_44665/3300233439.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m class_weight_dict[\u001b[39m1\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/weasel/reps/ai-seizure-detectives/RNN_workflow.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bdebian/home/weasel/reps/ai-seizure-detectives/RNN_workflow.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mrun\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmodel_rnn.ipynb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/reps/ai-seizure-detectives/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2454\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2452\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2453\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2454\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2456\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2457\u001b[0m \u001b[39m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2458\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/reps/ai-seizure-detectives/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:737\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[39mwith\u001b[39;00m preserve_keys(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns, \u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns[\u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m filename\n\u001b[0;32m--> 737\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49msafe_execfile_ipy(filename, raise_exceptions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    738\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[39m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[0;32m~/reps/ai-seizure-detectives/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2976\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[0;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[1;32m   2974\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_cell(cell, silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, shell_futures\u001b[39m=\u001b[39mshell_futures)\n\u001b[1;32m   2975\u001b[0m \u001b[39mif\u001b[39;00m raise_exceptions:\n\u001b[0;32m-> 2976\u001b[0m     result\u001b[39m.\u001b[39;49mraise_error()\n\u001b[1;32m   2977\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39msuccess:\n\u001b[1;32m   2978\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/reps/ai-seizure-detectives/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:292\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_before_exec\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_in_exec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_in_exec\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/tmp/ipykernel_44665/3300233439.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m class_weight_dict[\u001b[39m1\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "%run model_rnn.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
