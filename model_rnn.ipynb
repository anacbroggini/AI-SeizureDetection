{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from source import data_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential # intitialize the ANN\n",
    "from keras.layers import Dense, Activation, Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 30, 71)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('data/feature_extract_reshaped_all.npy')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((351, 30, 71), (88, 30, 71))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train and test set\n",
    "\n",
    "train_split_ratio = int((data.shape[0])*0.8)  # the first dimensio is epoch, and we are splitting the epochs between train anf test\n",
    "train_data = data[:train_split_ratio,:,:]\n",
    "test_data = data[train_split_ratio:,:,:]\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 30)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target =train_data[:,:,-1]\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 30, 70)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features =train_data[:,:,:-1]\n",
    "features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = train_data[:,:,:-1]\n",
    "y_train = train_data[:,:,-1]\n",
    "X_test = test_data[:,:,:-1]\n",
    "y_test = test_data[:,:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 30, 70)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 4)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.constant(X_train, dtype=tf.float32)\n",
    "lstm = tf.keras.layers.LSTM(4)\n",
    "output = lstm(inputs)\n",
    "print(output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 30, 4)\n",
      "(351, 4)\n",
      "(351, 4)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.constant(X_train, dtype=tf.float32)\n",
    "lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True)\n",
    "whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n",
    "print(whole_seq_output.shape)\n",
    "print(final_memory_state.shape)\n",
    "print(final_carry_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([351, 30, 70])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape=X_train.shape[1:]\n",
    "shape\n",
    "\n",
    "y_train_1d = y_train.max(axis=1)\n",
    "y_train_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = np.isnan(y_train)\n",
    "np.any(positions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=X_train.shape[1:]))\n",
    "\n",
    "# Recurrent layer\n",
    "model.add(LSTM(64, return_sequences=False, \n",
    "               dropout=0.1, recurrent_dropout=0.1))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Dropout for regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "learning_rate = 0.001\n",
    "adam_optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 6s 28ms/step - loss: 0.4928 - accuracy: 0.8575\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.4326 - accuracy: 0.8604\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4083 - accuracy: 0.8604\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4320 - accuracy: 0.8604\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4215 - accuracy: 0.8604\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4087 - accuracy: 0.8604\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4314 - accuracy: 0.8604\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8604\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.4315 - accuracy: 0.8604\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4024 - accuracy: 0.8604\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,  y_train_1d, \n",
    "                    # batch_size=2048, \n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14237745],\n",
       "       [0.13149945],\n",
       "       [0.14296146],\n",
       "       [0.1331521 ],\n",
       "       [0.13313702],\n",
       "       [0.1301522 ],\n",
       "       [0.13027324],\n",
       "       [0.12999949],\n",
       "       [0.13377638],\n",
       "       [0.1437609 ],\n",
       "       [0.14166959],\n",
       "       [0.13573408],\n",
       "       [0.16858   ],\n",
       "       [0.13799025],\n",
       "       [0.13615131],\n",
       "       [0.1377168 ],\n",
       "       [0.13006574],\n",
       "       [0.13114205],\n",
       "       [0.13068748],\n",
       "       [0.1323889 ],\n",
       "       [0.1392377 ],\n",
       "       [0.13349335],\n",
       "       [0.13514687],\n",
       "       [0.13559957],\n",
       "       [0.14658883],\n",
       "       [0.13928244],\n",
       "       [0.15004362],\n",
       "       [0.1458116 ],\n",
       "       [0.15559104],\n",
       "       [0.14691241],\n",
       "       [0.13859473],\n",
       "       [0.13941905],\n",
       "       [0.1599555 ],\n",
       "       [0.15309758],\n",
       "       [0.16385478],\n",
       "       [0.13886087],\n",
       "       [0.13747099],\n",
       "       [0.1345817 ],\n",
       "       [0.14857478],\n",
       "       [0.16089748],\n",
       "       [0.15204145],\n",
       "       [0.14465776],\n",
       "       [0.14352669],\n",
       "       [0.1493115 ],\n",
       "       [0.14560072],\n",
       "       [0.1569815 ],\n",
       "       [0.14645132],\n",
       "       [0.14391387],\n",
       "       [0.1463404 ],\n",
       "       [0.1643562 ],\n",
       "       [0.14104733],\n",
       "       [0.14828283],\n",
       "       [0.15505807],\n",
       "       [0.14248088],\n",
       "       [0.14550921],\n",
       "       [0.14778559],\n",
       "       [0.16659155],\n",
       "       [0.15999608],\n",
       "       [0.13684724],\n",
       "       [0.14491445],\n",
       "       [0.15249413],\n",
       "       [0.13650222],\n",
       "       [0.15148047],\n",
       "       [0.13813078],\n",
       "       [0.15980259],\n",
       "       [0.16919497],\n",
       "       [0.1716509 ],\n",
       "       [0.16322805],\n",
       "       [0.18105547],\n",
       "       [0.17446157],\n",
       "       [0.15676822],\n",
       "       [0.16389373],\n",
       "       [0.16551971],\n",
       "       [0.16862515],\n",
       "       [0.1514923 ],\n",
       "       [0.1750012 ],\n",
       "       [0.16939221],\n",
       "       [0.16004856],\n",
       "       [0.14465128],\n",
       "       [0.13821676],\n",
       "       [0.16090092],\n",
       "       [0.13647848],\n",
       "       [0.15274559],\n",
       "       [0.13693668],\n",
       "       [0.17869632],\n",
       "       [0.14952794],\n",
       "       [0.16970916],\n",
       "       [0.17032167]], dtype=float32)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# # Create callbacks\n",
    "# callbacks = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.8612\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.8612\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.8612\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.8612\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.8612\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.8612\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.8612\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.8612\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.8612\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,  y_train.astype(int), \n",
    "                    # batch_size=2048, \n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_model(input_shape):\n",
    "#     input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "#     conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "#     conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "#     conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "#     conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "#     conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "#     conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "#     conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "#     conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "#     conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "#     gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "#     output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "#     return keras.models.Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_model(input_shape=X_train.shape[1:])\n",
    "# keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 500\n",
    "# batch_size = 32\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\n",
    "#         \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "#     ),\n",
    "#     keras.callbacks.ReduceLROnPlateau(\n",
    "#         monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "#     ),\n",
    "#     keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "# ]\n",
    "# model.compile(\n",
    "#     optimizer=\"adam\",\n",
    "#     loss=\"sparse_categorical_crossentropy\",\n",
    "#     metrics=[\"sparse_categorical_accuracy\"],\n",
    "# )\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     batch_size=batch_size,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=callbacks,\n",
    "#     #validation_split=0.2,\n",
    "#     verbose=1,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs: A 3D tensor with shape [batch, timesteps, feature]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a sequential model\n",
    "# model = keras.Sequential()\n",
    "\n",
    "# # Add an input layer with an input shape of (time_steps, input_features)\n",
    "# model.add(layers.InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "\n",
    "# # Add a SimpleRNN layer with 32 units (neurons)\n",
    "# model.add(layers.SimpleRNN(32, activation='tanh'))\n",
    "\n",
    "# # Add the output layer with 1 neuron and sigmoid activation for binary classification\n",
    "# model.add(layers.Dense(30, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model with binary cross-entropy loss for binary classification\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 30, 70)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and y_train are your training data\n",
    "# model.fit(X_train, y_train, epochs=100, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14237745],\n",
       "       [0.13149945],\n",
       "       [0.14296146],\n",
       "       [0.1331521 ],\n",
       "       [0.13313702],\n",
       "       [0.1301522 ],\n",
       "       [0.13027324],\n",
       "       [0.12999949],\n",
       "       [0.13377638],\n",
       "       [0.1437609 ],\n",
       "       [0.14166959],\n",
       "       [0.13573408],\n",
       "       [0.16858   ],\n",
       "       [0.13799025],\n",
       "       [0.13615131],\n",
       "       [0.1377168 ],\n",
       "       [0.13006574],\n",
       "       [0.13114205],\n",
       "       [0.13068748],\n",
       "       [0.1323889 ],\n",
       "       [0.1392377 ],\n",
       "       [0.13349335],\n",
       "       [0.13514687],\n",
       "       [0.13559957],\n",
       "       [0.14658883],\n",
       "       [0.13928244],\n",
       "       [0.15004362],\n",
       "       [0.1458116 ],\n",
       "       [0.15559104],\n",
       "       [0.14691241],\n",
       "       [0.13859473],\n",
       "       [0.13941905],\n",
       "       [0.1599555 ],\n",
       "       [0.15309758],\n",
       "       [0.16385478],\n",
       "       [0.13886087],\n",
       "       [0.13747099],\n",
       "       [0.1345817 ],\n",
       "       [0.14857478],\n",
       "       [0.16089748],\n",
       "       [0.15204145],\n",
       "       [0.14465776],\n",
       "       [0.14352669],\n",
       "       [0.1493115 ],\n",
       "       [0.14560072],\n",
       "       [0.1569815 ],\n",
       "       [0.14645132],\n",
       "       [0.14391387],\n",
       "       [0.1463404 ],\n",
       "       [0.1643562 ],\n",
       "       [0.14104733],\n",
       "       [0.14828283],\n",
       "       [0.15505807],\n",
       "       [0.14248088],\n",
       "       [0.14550921],\n",
       "       [0.14778559],\n",
       "       [0.16659155],\n",
       "       [0.15999608],\n",
       "       [0.13684724],\n",
       "       [0.14491445],\n",
       "       [0.15249413],\n",
       "       [0.13650222],\n",
       "       [0.15148047],\n",
       "       [0.13813078],\n",
       "       [0.15980259],\n",
       "       [0.16919497],\n",
       "       [0.1716509 ],\n",
       "       [0.16322805],\n",
       "       [0.18105547],\n",
       "       [0.17446157],\n",
       "       [0.15676822],\n",
       "       [0.16389373],\n",
       "       [0.16551971],\n",
       "       [0.16862515],\n",
       "       [0.1514923 ],\n",
       "       [0.1750012 ],\n",
       "       [0.16939221],\n",
       "       [0.16004856],\n",
       "       [0.14465128],\n",
       "       [0.13821676],\n",
       "       [0.16090092],\n",
       "       [0.13647848],\n",
       "       [0.15274559],\n",
       "       [0.13693668],\n",
       "       [0.17869632],\n",
       "       [0.14952794],\n",
       "       [0.16970916],\n",
       "       [0.17032167]], dtype=float32)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/weasel/reps/ai-seizure-detectives/model_rnn.ipynb Cell 32\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bdebian/home/weasel/reps/ai-seizure-detectives/model_rnn.ipynb#Y244sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m precision_score, recall_score\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bdebian/home/weasel/reps/ai-seizure-detectives/model_rnn.ipynb#Y244sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred_c \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mround()\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bdebian/home/weasel/reps/ai-seizure-detectives/model_rnn.ipynb#Y244sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m precision \u001b[39m=\u001b[39m precision_score(y_test, y_pred_c, average\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmacro\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bdebian/home/weasel/reps/ai-seizure-detectives/model_rnn.ipynb#Y244sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m recall \u001b[39m=\u001b[39m recall_score(y_test, y_pred_c, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bdebian/home/weasel/reps/ai-seizure-detectives/model_rnn.ipynb#Y244sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m~/reps/ai-seizure-detectives/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1954\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[1;32m   1826\u001b[0m     y_true,\n\u001b[1;32m   1827\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1834\u001b[0m ):\n\u001b[1;32m   1835\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m \n\u001b[1;32m   1837\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1954\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1955\u001b[0m         y_true,\n\u001b[1;32m   1956\u001b[0m         y_pred,\n\u001b[1;32m   1957\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1958\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1959\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1960\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1961\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1962\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[1;32m   1964\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/reps/ai-seizure-detectives/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/reps/ai-seizure-detectives/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1375\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/reps/ai-seizure-detectives/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "y_pred_c = y_pred.round().astype(int)\n",
    "precision = precision_score(y_test, y_pred_c, average='macro')\n",
    "recall = recall_score(y_test, y_pred_c, average='macro')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
