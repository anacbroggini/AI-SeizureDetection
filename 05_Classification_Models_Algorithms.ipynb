{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from source import data_import\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/source/../data/feature_extracted.arrow was loaded.\n"
     ]
    }
   ],
   "source": [
    "df = data_import.load_pyarrow(file_name=\"feature_extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seizure_id</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>is_seizure</th>\n",
       "      <th>F4-C4_std</th>\n",
       "      <th>F4-C4_var</th>\n",
       "      <th>F4-C4_mean</th>\n",
       "      <th>F4-C4_abs_mean</th>\n",
       "      <th>F4-C4_delta</th>\n",
       "      <th>F4-C4_theta</th>\n",
       "      <th>F4-C4_gamma</th>\n",
       "      <th>...</th>\n",
       "      <th>FP1-F3_delta</th>\n",
       "      <th>FP1-F3_theta</th>\n",
       "      <th>FP1-F3_gamma</th>\n",
       "      <th>CZ-PZ_std</th>\n",
       "      <th>CZ-PZ_var</th>\n",
       "      <th>CZ-PZ_mean</th>\n",
       "      <th>CZ-PZ_abs_mean</th>\n",
       "      <th>CZ-PZ_delta</th>\n",
       "      <th>CZ-PZ_theta</th>\n",
       "      <th>CZ-PZ_gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>25.278278</td>\n",
       "      <td>638.991344</td>\n",
       "      <td>0.642823</td>\n",
       "      <td>19.767362</td>\n",
       "      <td>99.724544</td>\n",
       "      <td>33.651173</td>\n",
       "      <td>0.131576</td>\n",
       "      <td>...</td>\n",
       "      <td>115.680103</td>\n",
       "      <td>29.233559</td>\n",
       "      <td>0.343249</td>\n",
       "      <td>35.447713</td>\n",
       "      <td>1256.540374</td>\n",
       "      <td>0.758870</td>\n",
       "      <td>27.466555</td>\n",
       "      <td>194.364620</td>\n",
       "      <td>76.886992</td>\n",
       "      <td>0.174189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>24.908361</td>\n",
       "      <td>620.426452</td>\n",
       "      <td>0.459926</td>\n",
       "      <td>19.018136</td>\n",
       "      <td>80.467433</td>\n",
       "      <td>30.739370</td>\n",
       "      <td>0.113581</td>\n",
       "      <td>...</td>\n",
       "      <td>98.999296</td>\n",
       "      <td>24.519002</td>\n",
       "      <td>0.363930</td>\n",
       "      <td>33.861154</td>\n",
       "      <td>1146.577756</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>24.488472</td>\n",
       "      <td>187.417290</td>\n",
       "      <td>34.401955</td>\n",
       "      <td>0.181605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>25.078313</td>\n",
       "      <td>628.921793</td>\n",
       "      <td>-0.336786</td>\n",
       "      <td>18.864175</td>\n",
       "      <td>97.815139</td>\n",
       "      <td>19.120020</td>\n",
       "      <td>0.108965</td>\n",
       "      <td>...</td>\n",
       "      <td>76.273119</td>\n",
       "      <td>21.891098</td>\n",
       "      <td>0.347473</td>\n",
       "      <td>30.472674</td>\n",
       "      <td>928.583879</td>\n",
       "      <td>0.139786</td>\n",
       "      <td>23.040842</td>\n",
       "      <td>117.606520</td>\n",
       "      <td>31.998680</td>\n",
       "      <td>0.155509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>23.796227</td>\n",
       "      <td>566.260437</td>\n",
       "      <td>0.571550</td>\n",
       "      <td>18.298645</td>\n",
       "      <td>78.057846</td>\n",
       "      <td>22.859691</td>\n",
       "      <td>0.112154</td>\n",
       "      <td>...</td>\n",
       "      <td>111.418632</td>\n",
       "      <td>24.584840</td>\n",
       "      <td>0.326450</td>\n",
       "      <td>30.803236</td>\n",
       "      <td>948.839359</td>\n",
       "      <td>0.347514</td>\n",
       "      <td>23.812672</td>\n",
       "      <td>158.377845</td>\n",
       "      <td>31.605055</td>\n",
       "      <td>0.181355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>28.030262</td>\n",
       "      <td>785.695596</td>\n",
       "      <td>-0.156618</td>\n",
       "      <td>21.895794</td>\n",
       "      <td>102.786435</td>\n",
       "      <td>31.697164</td>\n",
       "      <td>0.123064</td>\n",
       "      <td>...</td>\n",
       "      <td>115.905093</td>\n",
       "      <td>37.751880</td>\n",
       "      <td>0.323275</td>\n",
       "      <td>39.120852</td>\n",
       "      <td>1530.441051</td>\n",
       "      <td>-0.032786</td>\n",
       "      <td>29.786483</td>\n",
       "      <td>215.122132</td>\n",
       "      <td>60.283108</td>\n",
       "      <td>0.170928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   seizure_id  segment_id  is_seizure  F4-C4_std   F4-C4_var  F4-C4_mean  \\\n",
       "0           0           1       False  25.278278  638.991344    0.642823   \n",
       "1           0           2       False  24.908361  620.426452    0.459926   \n",
       "2           0           3       False  25.078313  628.921793   -0.336786   \n",
       "3           0           4       False  23.796227  566.260437    0.571550   \n",
       "4           0           5       False  28.030262  785.695596   -0.156618   \n",
       "\n",
       "   F4-C4_abs_mean  F4-C4_delta  F4-C4_theta  F4-C4_gamma  ...  FP1-F3_delta  \\\n",
       "0       19.767362    99.724544    33.651173     0.131576  ...    115.680103   \n",
       "1       19.018136    80.467433    30.739370     0.113581  ...     98.999296   \n",
       "2       18.864175    97.815139    19.120020     0.108965  ...     76.273119   \n",
       "3       18.298645    78.057846    22.859691     0.112154  ...    111.418632   \n",
       "4       21.895794   102.786435    31.697164     0.123064  ...    115.905093   \n",
       "\n",
       "   FP1-F3_theta  FP1-F3_gamma  CZ-PZ_std    CZ-PZ_var  CZ-PZ_mean  \\\n",
       "0     29.233559      0.343249  35.447713  1256.540374    0.758870   \n",
       "1     24.519002      0.363930  33.861154  1146.577756    0.040398   \n",
       "2     21.891098      0.347473  30.472674   928.583879    0.139786   \n",
       "3     24.584840      0.326450  30.803236   948.839359    0.347514   \n",
       "4     37.751880      0.323275  39.120852  1530.441051   -0.032786   \n",
       "\n",
       "   CZ-PZ_abs_mean  CZ-PZ_delta  CZ-PZ_theta  CZ-PZ_gamma  \n",
       "0       27.466555   194.364620    76.886992     0.174189  \n",
       "1       24.488472   187.417290    34.401955     0.181605  \n",
       "2       23.040842   117.606520    31.998680     0.155509  \n",
       "3       23.812672   158.377845    31.605055     0.181355  \n",
       "4       29.786483   215.122132    60.283108     0.170928  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1138, 73)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to try without \"segment_id\"\n",
    "#drop_features = [\"segment_id\"]\n",
    "#model_df = df.drop(columns=drop_features)\n",
    "\n",
    "# Uncomment if you want to try with \"segment_id\"\n",
    "model_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_df[\"is_seizure\"]\n",
    "X = model_df.drop(columns=[\"is_seizure\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_models(X, y, models=None, cv=5, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
    "    \n",
    "    if models is None:\n",
    "        models = {\n",
    "            'Logistic Regression': {\n",
    "                'model': LogisticRegression(),\n",
    "                'params': {\n",
    "                    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "                    'max_iter': [1000, 1500, 2000]\n",
    "                }\n",
    "            },\n",
    "            'Random Forest': {\n",
    "                'model': RandomForestClassifier(),\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200, 300],\n",
    "                    'max_depth': [None, 10, 20],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4],\n",
    "                    'max_features': ['auto', 'sqrt', 'log2']\n",
    "                }\n",
    "            },\n",
    "            'Gradient Boosting': {\n",
    "                'model': GradientBoostingClassifier(),\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200, 300],\n",
    "                    'learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'max_depth': [3, 5, 7],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4],\n",
    "                    'max_features': ['auto', 'sqrt', 'log2']\n",
    "                }\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'model': XGBClassifier(),\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200, 300],\n",
    "                    'learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'max_depth': [3, 5, 7],\n",
    "                    'min_child_weight': [1, 3, 5],\n",
    "                    'gamma': [0, 0.1, 0.2],\n",
    "                    'subsample': [0.8, 0.9, 1.0],\n",
    "                    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "                }\n",
    "            },\n",
    "            # Add more models here\n",
    "        }\n",
    "\n",
    "    for model_name, model_info in models.items():\n",
    "        print(f\"Model: {model_name}\")\n",
    "        \n",
    "        if isinstance(model_info, dict):\n",
    "            model = model_info['model']\n",
    "            param_grid = model_info['params']\n",
    "            grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy')\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "        else:\n",
    "            model = model_info\n",
    "            best_model = model\n",
    "        \n",
    "        # Train the best model on the training data\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test data\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Calculate and display the confusion matrix\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion)\n",
    "        \n",
    "        # Generate a classification report with various metrics\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "        \n",
    "        # Plot the confusion matrix\n",
    "        labels = ['No Seizure', 'Seizure']\n",
    "        mat = confusion.T  # Transpose to match your reference code\n",
    "        sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "        plt.xlabel('True label')\n",
    "        plt.ylabel('Predicted label')\n",
    "        plt.title(f'Confusion Matrix for {model_name}')\n",
    "        plt.show()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def run_classification_models(X, y, models=None, cv=5, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    if models is None:\n",
    "        models = {\n",
    "            'Logistic Regression': LogisticRegression(),\n",
    "            'Random Forest': RandomForestClassifier(),\n",
    "            'Support Vector Machine (SVM)': SVC(),\n",
    "            'Gradient Boosting': GradientBoostingClassifier(),\n",
    "            'XGBoost': XGBClassifier()  # Add XGBoost for classification\n",
    "            # Add more models here\n",
    "        }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Model: {model_name}\")\n",
    "        \n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate and display the confusion matrix\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion)\n",
    "        \n",
    "        # Generate a classification report with various metrics\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "        print()\n",
    "\n",
    "# Usage example:\n",
    "# X and y are your feature matrix and target variable\n",
    "# run_classification_models(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Confusion Matrix:\n",
      "[[176   1]\n",
      " [  9  42]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.99      0.97       177\n",
      "        True       0.98      0.82      0.89        51\n",
      "\n",
      "    accuracy                           0.96       228\n",
      "   macro avg       0.96      0.91      0.93       228\n",
      "weighted avg       0.96      0.96      0.95       228\n",
      "\n",
      "\n",
      "Model: Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[175   2]\n",
      " [  8  43]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.99      0.97       177\n",
      "        True       0.96      0.84      0.90        51\n",
      "\n",
      "    accuracy                           0.96       228\n",
      "   macro avg       0.96      0.92      0.93       228\n",
      "weighted avg       0.96      0.96      0.96       228\n",
      "\n",
      "\n",
      "Model: Support Vector Machine (SVM)\n",
      "Confusion Matrix:\n",
      "[[177   0]\n",
      " [ 22  29]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      1.00      0.94       177\n",
      "        True       1.00      0.57      0.72        51\n",
      "\n",
      "    accuracy                           0.90       228\n",
      "   macro avg       0.94      0.78      0.83       228\n",
      "weighted avg       0.91      0.90      0.89       228\n",
      "\n",
      "\n",
      "Model: Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[177   0]\n",
      " [  4  47]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      1.00      0.99       177\n",
      "        True       1.00      0.92      0.96        51\n",
      "\n",
      "    accuracy                           0.98       228\n",
      "   macro avg       0.99      0.96      0.97       228\n",
      "weighted avg       0.98      0.98      0.98       228\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Confusion Matrix:\n",
      "[[177   0]\n",
      " [  2  49]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99       177\n",
      "        True       1.00      0.96      0.98        51\n",
      "\n",
      "    accuracy                           0.99       228\n",
      "   macro avg       0.99      0.98      0.99       228\n",
      "weighted avg       0.99      0.99      0.99       228\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classification_models(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
