{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We wannt to increase the data for training!!!  \n",
    "- we will shift one segment step backwards from the seizure onset to create more batches(epochs) of sequences\n",
    "- First we take more segments -  60 segments from the original data, when using data import\n",
    "- we want have training length of 30 segments in total. \n",
    "- Starting from the segment 60th right before seizure, walking backwards with step of 1 segment, having blocks of 30 segments (training length) until we reach the 0th\n",
    "- Thats how we increase the training data by 30 times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clips_preictal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/Model_sequences.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/Model_sequences.ipynb#W1sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m stride \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/Model_sequences.ipynb#W1sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m block_s \u001b[39m=\u001b[39m \u001b[39m60\u001b[39m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/Model_sequences.ipynb#W1sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m X_1, Y_1 \u001b[39m=\u001b[39m lstm_build_input(clips_preictal, \u001b[39m1\u001b[39m, window, stride)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/Model_sequences.ipynb#W1sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m X_0, Y_0 \u001b[39m=\u001b[39m lstm_build_input(clips_interictal, \u001b[39m0\u001b[39m, window, stride)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Samet/Documents/Bildung/BootcampSpiced/github_rice_regression/Capstone_project/ai2/Model_sequences.ipynb#W1sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m \u001b[39m# Scale the data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clips_preictal' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Construct LSTM sequences from one segment\n",
    "def lstm_sequence(input_segment, target, sampling_freq, window, stride, block_s = 60):\n",
    "    \"\"\" Function for generating blocks of LSTM input tensors\n",
    "        input_segment : The EEG segment\n",
    "        target        : 1/0 (preictal/interictial); None for test\n",
    "        sampling_freq : Samplig frequency\n",
    "        window        : Window size for 1d convolutions on each block\n",
    "        stride        : Stride size of the 1d convolution\n",
    "        block_s       : Size of the block in seconds (default = 60)\n",
    "    \"\"\"\n",
    "\n",
    "    # Dimensions\n",
    "    n_channels, T_segment = input_segment.shape\n",
    "\n",
    "    # Determine block dimensions\n",
    "    block_len = sampling_freq * block_s   # Length of each block\n",
    "    n_blocks = (T_segment-1) // block_len # Number of blocks\n",
    "    blocks = [block for block in range(0,(n_blocks+1)*block_len,block_len)]\n",
    "\n",
    "    # Determine the sequence length for LSTM\n",
    "    div = (block_len - window)%stride\n",
    "    if (div != 0):\n",
    "        pad = stride - div # Size of padding neded\n",
    "    else:\n",
    "        pad = 0\n",
    "\n",
    "    seq_len = (block_len + pad - window) // stride\n",
    "\n",
    "    # Initiate tensor\n",
    "    X = np.zeros((n_blocks, seq_len, n_channels))\n",
    "\n",
    "    # Loop over blocks and fill X\n",
    "    for ib in range(n_blocks):\n",
    "        # Get block\n",
    "        data_block = input_segment[:, blocks[ib]:blocks[ib+1]]\n",
    "\n",
    "        # Pad if necessary\n",
    "        if (pad !=0):\n",
    "            data_block = np.concatenate((data_block, np.zeros((n_channels, pad))), axis=1)\n",
    "\n",
    "        # 1d convolution by mean\n",
    "        index = 0\n",
    "        for j in range(seq_len):\n",
    "            X[ib, j, :] = np.mean(data_block[:, (index+j):(index+j+seq_len)], axis = 1)\n",
    "\n",
    "    # Fill in the target\n",
    "    if (target == 1):\n",
    "        Y = np.ones(n_blocks)\n",
    "    elif(target == 0):\n",
    "        Y = np.zeros(n_blocks)\n",
    "    else:\n",
    "        Y = None\n",
    "\n",
    "    return X, Y, n_blocks\n",
    "\n",
    "# Collect all the segments to build a tesnsor input for LSTM\n",
    "def lstm_build_input(clips, target, window, stride, block_s = 60):\n",
    "    \"\"\" Collect all the data and build sequences for LSTM\n",
    "        clips              : List of clips\n",
    "        target             : 1/0 (preictal/interictial); None for test set\n",
    "        window             : Window size for 1d convolutions\n",
    "        stride             : Length of the stride in 1d convolution\n",
    "        block_s            : Size of the block in seconds (default = 60)\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of clips\n",
    "    n_clips = len(clips)\n",
    "\n",
    "    # Loop over all clips and store data\n",
    "    iclip = 0\n",
    "    for file in clips:\n",
    "        clip = loadmat(file)\n",
    "        segment_name = list(clip.keys())[3] # Get segment name\n",
    "        input_segment = clip[segment_name][0][0][0] # Get electrode data\n",
    "        sampling_freq = np.squeeze(clip[segment_name][0][0][2]) # Sampling frequency\n",
    "\n",
    "        # Get number of channels\n",
    "        n_channels = clip[segment_name][0][0][0].shape[0]\n",
    "\n",
    "        # Get tensor input and targets from blocks\n",
    "        X, Y, n_blocks = lstm_sequence(input_segment, target, sampling_freq, window, stride, block_s)\n",
    "\n",
    "        # Concatenate the tensor and target vector\n",
    "        if (iclip == 0):\n",
    "            X_train = X\n",
    "            Y_train = Y[:,None] if Y is not None else None\n",
    "        else:\n",
    "            X_train = np.vstack((X_train,X))\n",
    "            Y_train = np.vstack((Y_train,Y[:,None])) if Y is not None else None\n",
    "\n",
    "        iclip +=1\n",
    "\n",
    "    return X_train, Y_train\n",
    "\n",
    "\n",
    "# Window, stride and block_s\n",
    "window = 16000\n",
    "stride = 100\n",
    "block_s = 60\n",
    "\n",
    "X_1, Y_1 = lstm_build_input(clips_preictal, 1, window, stride)\n",
    "X_0, Y_0 = lstm_build_input(clips_interictal, 0, window, stride)\n",
    "\n",
    "# Scale the data\n",
    "X_1 = X_1 / np.max(np.abs(X_1), axis=1)[:,None,:]\n",
    "X_0 = X_0 / np.max(np.abs(X_0), axis=1)[:,None,:]\n",
    "\n",
    "# Combine the data\n",
    "X = np.concatenate((X_0, X_1), axis = 0)\n",
    "Y = np.concatenate((Y_0, Y_1), axis = 0)\n",
    "Y = np.squeeze(Y)\n",
    "\n",
    "print(\"Data shape = \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode for Data Augumentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have a DataFrame 'dataset after feature extraction' with features and a binary target 'before_seizure'\n",
    "# Replace 'dataset after feature extraction' with your actual DataFrame and column names\n",
    "\n",
    "def augment_data( original_dataset , training_length=30):\n",
    "    augmented_data = []\n",
    "\n",
    "    # Iterate over the rows of the original data\n",
    "    for i in range(len(original_dataset)):\n",
    "        # Check if the current row represents a before seizure sequence (positive class)\n",
    "        if original_dataset.iloc[i]['before_seizure'] == 1:\n",
    "            # Shift one segment step backward and create training batches\n",
    "            for j in range(i, max(i - training_length, -1), -1):\n",
    "                if j - training_length + 1 >= 0:\n",
    "                    # Extract features and target for the training batch\n",
    "                    features_batch = original_dataset.iloc[j - training_length + 1:j + 1, :-1]  # Exclude the target column\n",
    "                    target_batch = original_dataset.iloc[j]['before_seizure']\n",
    "\n",
    "                    # Append the training batch to the augmented data , do we want to append it to the dataset ? or just return it ?\n",
    "                    augmented_data.append((features_batch, target_batch)) \n",
    "\n",
    "    # Convert the augmented data to a new DataFrame if needed\n",
    "    augmented_df = pd.DataFrame(augmented_data, columns=['features', 'before_seizure'])\n",
    "\n",
    "    return augmented_df\n",
    "\n",
    "# Example usage\n",
    "augmented_df = augment_data(\"dataset after feature extraction\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
